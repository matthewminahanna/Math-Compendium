\begin{dfn}\label{def:inner-product}
    An \vocab{inner product} on a vector space \( \mathbf{V} \) is a map 
    \begin{align*}
        \cdot : & \mathbf{V} \times \mathbf{V} \to \mathbb{K} \\
        & \left( \vb{u},\vb{v} \right) \mapsto \left< \vb{u},\vb{v} \right>
    \end{align*}
    such that all of the following criteria are held:
    \begin{description}
        \item[\textbf{Non-negative:}] \( \left< \vb{v},\vb{v} \right> \ge 0 \) for all \( \vb{v} \in \mathbf{V} \). 
        \item[\textbf{Definiteness:}] \( \left< \vb{v},\vb{v} \right> = 0 \) if and only if \( \vb{v} = \vb{0} \).
        \item[\textbf{Linearity in the first argument:}] \( \left< \vb{u} + \lambda \vb{v}, \vb{w} \right>  = \left<  \vb{u}, \vb{w} \right> + \lambda \left<  \vb{v},\vb{w} \right>\) for all \( \vb{u}, \vb{v}, \vb{w} \in \mathbf{V} \) and \( \lambda \in \mathbb{K} \).
        \item[\textbf{Conjugate symmetry:}] \( \left< \vb{u}, \vb{v} \right> = \overline{\left< \vb{v},\vb{u} \right>} \) for all \( \vb{u},\vb{v} \in \mathbf{V} \). 
    \end{description}
    If \( \mathbf{V} \) has an inner product defined, we call \( \mathbf{V} \) an \vocab{inner product space}.
\end{dfn}

\textbf{Note.} Some older texts refer to inner product spaces as \vocab{pre-Hilbert spaces}. The prefix “pre” will make sense once you study functional analysis.


\begin{lemma}
    An inner product on a vector space \( \mathbf{V} \) is conjugate linear in the second component. That is: 
    \[ \left< \vb{u}, \vb{v} + \lambda \vb{w} \right>  = \left< \vb{u},\vb{v} \right> + \overline{\lambda} \left< \vb{u},\vb{w} \right>.\]
\end{lemma}
\begin{proof}
    We have 
    \begin{align*}
        \left< \vb{u}, \vb{v} + \lambda \vb{w} \right> &= \overline{ \left< \vb{v} + \lambda \vb{w}, \vb{u} \right>} \\
        &= \overline{ \left< \vb{v}, \vb{u} \right> + \lambda \left< \vb{w}, \vb{u} \right>} \\
        &= \overline{ \left<  \vb{v}, \vb{u} \right>} + \overline{\lambda} \overline{ \left< \vb{w}, \vb{u} \right>} \\
        &= \overline{ \overline{\left<  \vb{u}, \vb{v} \right> }} + \overline{ \lambda} \overline{ \overline{ \left< \vb{u}, \vb{w} \right>}} \\
        &= \left< \vb{u},\vb{v} \right> + \overline{\lambda} \left< \vb{u},\vb{w} \right>
    \end{align*}
    
\end{proof}


\begin{exercise}\label{exc:expand-ip-diff}
    Let \( \vb{v}_{1}, \vb{v}_{2}, \vb{w}_{1}, \vb{w}_{2} \) be vectors in an inner product space \( \mathbf{V} \). Show that 
    \[ \left< \vb{v}_{1}, \vb{w}_{1} \right> - \left< \vb{v}_{2}, \vb{w}_{2} \right> = \left< \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{1} -\vb{w}_{2} \right> + \left< \vb{v}_{2} , \vb{w}_{1} -\vb{w}_{2} \right> + \left<  \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{2} \right>\]
\end{exercise}
\begin{solution}
    Just calculate the right hand side. 
    \begin{align*}
         \left< \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{1} -\vb{w}_{2} \right> + \left< \vb{v}_{2} , \vb{w}_{1} -\vb{w}_{2} \right> + \left<  \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{2} \right> &= \left< \vb{v}_{1}, \vb{w}_{1} - \vb{w}_{2} \right> - \left< \vb{v}_{2}, \vb{w}_{1} - \vb{w}_{2} \right> + \left< \vb{v}_{2} , \vb{w}_{1} -\vb{w}_{2} \right> + \left<  \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{2} \right>\\ 
         &= \left<  \vb{v}_{1}, \vb{w}_{1} - \vb{w}_{2} \right> - \Ccancel[DeepRed]{\left< \vb{v}_{2}, \vb{w}_{1} - \vb{w}_{2} \right>}  + \Ccancel[DeepRed]{\left< \vb{v}_{2}, \vb{w}_{1} - \vb{w}_{2} \right>} + \left<  \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{2} \right> \\
         &= \left<  \vb{v}_{1}, \vb{w}_{1} - \vb{w}_{2} \right> + \left<  \vb{v}_{1}-\vb{v}_{2}, \vb{w}_{2} \right> \\
         &= \left< \vb{v}_{1}, \vb{w}_{1} \right> - \left< \vb{v}_{1}, \vb{w}_{2} \right> + \left< \vb{v}_{1}, \vb{w}_{2} \right> - \left< \vb{v}_{2}, \vb{w}_{2} \right> \\
         &=  \left< \vb{v}_{1}, \vb{w}_{1} \right> - \Ccancel[DeepRed]{ \left< \vb{v}_{1}, \vb{w}_{2} \right>} + \Ccancel[DeepRed]{ \left< \vb{v}_{1}, \vb{w}_{2} \right>} - \left< \vb{v}_{2}, \vb{w}_{2} \right> \\
         &= \left< \vb{v}_{1}, \vb{w}_{1} \right> - \left< \vb{v}_{2}, \vb{w}_{2} \right>
    \end{align*}
    
\end{solution}


\begin{exercise}
    For a complex inner product space \( \mathbf{V} \), show that 
    \[ \Im \left( \left< \vb{v},\vb{w} \right> \right) = \Re \left( \left< \vb{v}, i \vb{w} \right> \right) \quad  \text{for all } \vb{v}, \vb{w} \in \mathbf{V}.\]
\end{exercise}
\begin{solution}
    Suppose that \( \left< \vb{v}, \vb{w} \right> = a+bi \). Then, by conjugate linearity in the second component, we have 
    \begin{align*}
        \left< \vb{v}, i \vb{w} \right>&= \overline{i} \left< \vb{v},\vb{w} \right> \\
        &= -i \left< \vb{v},\vb{w} \right> \\
        &= -i \left( a+bi \right) \\
        &= b - ai
    \end{align*}
    It is clear that \( \Im (a+bi) = \Re (b-ai) \).
\end{solution}

\begin{dfn}
    Suppose that \( \mathbf{V} \) is an inner-product space. If \( \vb{v}, \vb{w} \in \mathbf{V}\) have the property that \( \left< \vb{v},\vb{w} \right> =0\), we say that \( \vb{v} \) and \( \vb{w} \) are \vocab{orthogonal} and sometimes write \( \vb{v} \perp \vb{w} \). Note that the zero vector is orthogonal to every vector in \( \mathbf{V} \).
\end{dfn}

\begin{example}
    Suppose that \( \vb{x} \perp \vb{y} \) and \( \vb{y} \perp \vb{z} \). Is it necessarily true that \( \vb{x} \perp \vb{z} \)?\\
    No. For a counterexample, take \( \vb{x} = \vb{z} \neq \vb{0} \). Then \( \left< \vb{x}, \vb{y} \right> = 0 \) and \( \left< \vb{y}, \vb{z} \right> = 0 \) are satisfied, but \( \left< \vb{x}, \vb{z} \right> \neq 0 \).\\
    Alternatively, take \( \vb{y} = \vb{0} \) and choose any \( \vb{x} \) and \( \vb{z} \) such that \( \left< \vb{x}, \vb{z} \right> \neq 0 \).
\end{example}



\begin{lemma}
    Let \( S \) be a subset of an inner product space \( \mathbf{V} \). The set 
    \[ S^{\perp} = \left\{ \vb{v} \in \mathbf{V} \ \middle| \  \left< \vb{v},\vb{s} \right> = 0 \text{ for all } \vb{s} \in S \right\} \]
    is a subspace of \( \mathbf{V} \).
\end{lemma}
\begin{proof}
    Clearly \( \vb{0} \in S^{\perp} \). If \( \vb{v}, \vb{w} \in S^{\perp} \) and \( \lambda \in \mathbb{K}\), then for any \( \vb{s} \in S \) we have
    \begin{align*}
        \left< \vb{v} + \lambda \vb{w}, \vb{s} \right> &= \left<  \vb{v},\vb{s} \right> + \lambda \left< \vb{w}, \vb{s} \right> \\ 
        &= 0 + \lambda \cdot 0 \\
        &= 0
    \end{align*}
    So \( S^{\perp} \) is a subspace of \( \mathbf{V} \). We call \( S^{\perp} \) the \vocab{orthogonal complement} of \( S \). In speech, \( S^{\perp} \) is often read as “S perp.”
\end{proof}

\begin{exercise}
    Show that 
    \[ S^{\perp} = \left( \mathrm{span}(S) \right)^{\perp} \]
\end{exercise}
\begin{solution}
    Clearly \( \left( \mathrm{span}(S) \right)^{\perp} \subseteq S^{\perp}  \) since \( S \subseteq \mathrm{span}(S) \). Now pick \( \vb{v} \in S^{\perp } \) and pick any \( \vb{s} \in \mathrm{span}(S) \). Therefore \( \vb{s} = \sum_{k=1}^{n} \lambda_{k} \vb{s}_{k} \) for \( \vb{s}_{k} \in S \). So 
    \begin{align*}
        \left< \vb{v},\vb{s} \right> &= \left< \vb{v}, \sum_{k=1}^{n} \lambda_{k} \vb{s}_{k} \right> \\
        &= \sum_{k =1}^{n} \overline{\lambda_{k}} \left< \vb{v},\vb{s}_{k} \right> \\
        &= \sum_{k =1}^{n} \overline{\lambda_{k}} \cdot 0 \tag{Since $\vb{v} \in S^{\perp}$} \\
        &= 0
    \end{align*}
    So \( \vb{v} \in \left( \mathrm{span}(S) \right)^{\perp} \)
\end{solution}



\subsection{Norms}

\begin{dfn}\label{def:norm}
    A \vocab{norm} is a map \( \norm{ \cdot }: \mathbf{V} \to \left[ 0, \infty \right) \), where we write \( \vb{v} \mapsto \norm{\vb{v}} \), such that: 
    \begin{enumerate}[label=\textbf{\roman*)}]
        \item \( \norm{\vb{v}} = 0 \) if and only if \( \vb{v} = \vb{0} \). 
        \item \( \norm{ \lambda \vb{v}} = \abs{\lambda} \;  \norm{\vb{v}} \) for all \( \lambda \in \mathbb{K} \) and \( \vb{v} \in \mathbf{V} \). 
        \item \( \norm{\vb{v} + \vb{w}} \le \norm{\vb{v}}+ \norm{\vb{w}}\) for all \( \vb{v} , \vb{w} \in \mathbf{V} \).
    \end{enumerate}
    If \( \mathbf{V} \) has a norm defined on it, we call the pair \( \left( \mathbf{V}, \norm{ \cdot} \right) \) a \vocab{normed vector space}. 
\end{dfn}


\begin{theorem}
    If \( \mathbf{V} \) is an inner-product space, then it is also a normed vector space whose \vocab{induced norm} is defined to be:
    \[ \norm{\vb{v}} := \sqrt{\left< \vb{v},\vb{v} \right>} .\]
\end{theorem}
\begin{proof}
 We need to show that \( \norm{\cdot} = \sqrt{\left< \cdot , \cdot \right>} \) satisfies the properties of a norm. \\[6pt]
Suppose \( \norm{\vb{v}} = 0 \). Then, by definition,
\[
    \sqrt{\left< \vb{v}, \vb{v} \right>} = 0
    \quad \Rightarrow \quad
    \left< \vb{v}, \vb{v} \right> = 0
    \quad \Rightarrow \quad
    \vb{v} = \vb{0}.
\]
Thus, \( \norm{\vb{v}} = 0 \) if and only if \( \vb{v} = \vb{0} \). (The reverse direction is obvious.) \\ 
Next, for any \( \lambda \in \mathbb{K} \) and \( \vb{v} \in \mathbf{V} \), we have 
\begin{align*}
    \norm{\lambda \vb{v}} &= \sqrt{ \left< \lambda \vb{v}, \lambda \vb{v} \right>} \\
    &= \sqrt{ \lambda \overline{\lambda} \left< \vb{v},\vb{v} \right>} \\
    &= \sqrt{ \abs{\lambda}^{2} \left<  \vb{v},\vb{v} \right>} \\
    &= \sqrt{\abs{\lambda}^{2}} \sqrt{ \left<  \vb{v},\vb{v} \right>} \\
    &= \abs{\lambda} \sqrt{\left< \vb{v},\vb{v} \right>} \\
    &= \abs{\lambda} \; \norm{\vb{v}}
\end{align*}
Thus, \( \norm{\lambda \vb{v}} = \abs{\lambda} \;  \norm{\vb{v}} \) for all \( \lambda \in \mathbb{K} \) and \( \vb{v} \in \mathbf{V} \). \\ 
Finally, 
\begin{align*}
    \norm{\vb{v} + \vb{w}} &= \sqrt{ \left<  \vb{v} + \vb{w}, \vb{v} + \vb{w} \right>} \\ 
    &= \sqrt{ \left<  \vb{v},\vb{v} \right> + \left< \vb{v}, \vb{w} \right> + \left< \vb{w},\vb{v} \right> + \left< \vb{w},\vb{w} \right>} \\
    &=  \sqrt{ \left<  \vb{v},\vb{v} \right> + \left< \vb{v}, \vb{w} \right> + \overline{\left< \vb{v},\vb{w} \right>} + \left< \vb{w},\vb{w} \right>} \\
    &= \sqrt{ \left<  \vb{v},\vb{v} \right> + 2 \Re \left[ \left< \vb{v},\vb{w} \right> \right]+ \left< \vb{w},\vb{w} \right>} \\
    & \le \sqrt{ \left< \vb{v},\vb{v} \right> + 2 \abs{\left< \vb{v},\vb{w} \right>} + \left< \vb{w},\vb{w} \right>} \\
    & \le \sqrt{ \left< \vb{v},\vb{v} \right> + 2 \left< \vb{v},\vb{v} \right>^{\frac{1}{2}}\left< \vb{w},\vb{w} \right>^{\frac{1}{2}} + \left< \vb{w},\vb{w} \right>} \tag{By the \hyperref[thrm:Complex Cauchy-Schwarz]{Cauchy–Schwarz inequality}} \\
    &= \sqrt{\left( \left< \vb{v},\vb{v} \right>^{\frac{1}{2}} + \left< \vb{w},\vb{w} \right>^{\frac{1}{2}}\right)^{2}}\\
    &= \sqrt{\left<  \vb{v},\vb{v} \right>} + \sqrt{\left< \vb{w},\vb{w} \right>}
\end{align*}
This shows that \( \norm{\vb{v} + \vb{w}} \le \norm{\vb{v}} + \norm{\vb{w}} \). This completes the proof.
\end{proof}


\begin{exercise}
    Show that \( \left< \vb{v},\vb{w} \right> = 0 \) if and only if 
    \[ \norm{ \vb{v} + \lambda \vb{w}} = \norm{\vb{v} - \lambda \vb{w}} \quad \text{ for all } \lambda \in \mathbb{K}. \]
\end{exercise}
\begin{solution}
    \( \left( \Rightarrow \right) \) Suppose that \( \left< \vb{v},\vb{w} \right>  = 0\). It suffices to show that \(  \norm{ \vb{v} + \lambda \vb{w}}^{2} = \norm{\vb{v} - \lambda \vb{w}}^{2}  \) for all \( \lambda \in \mathbb{K} \). We calculate
    \begin{align*}
        \norm{\vb{v} + \lambda \vb{w}}^{2} &= \left< \vb{v}+ \lambda \vb{w}, \vb{v}+ \lambda \vb{w} \right> \\
        &= \left< \vb{v}, \vb{v} + \lambda \vb{w} \right> +  \lambda \left< \vb{w},\vb{v} + \lambda \vb{w} \right> \\
        &= \left< \vb{v},\vb{v} \right> + \overline{\lambda} \left< \vb{v},\vb{w} \right> + \lambda \left<  \vb{w},\vb{v} \right> + \abs{\lambda}^{2} \left< \vb{w},\vb{w} \right>
    \end{align*}
    So 
    \begin{equation}\label{eqn:v-plus-lamba-w}
        \boxed{\norm{\vb{v} + \lambda \vb{w}}^{2} = \norm{\vb{v}}^{2} + \overline{\lambda} \left< \vb{v},\vb{w} \right> + \lambda \overline{ \left< \vb{v},\vb{w} \right>} + \abs{\lambda}^{2} \norm{\vb{w}}^{2}}
    \end{equation} 
    Similarly, calculating \( \norm{\vb{v} - \lambda \vb{w}}^{2} \), we have 
    \begin{align*}
        \norm{\vb{v} - \lambda \vb{w}}^{2} &= \left< \vb{v} - \lambda \vb{w}, \vb{v}- \lambda \vb{w} \right> \\
        &= \left< \vb{v}, \vb{v} - \lambda \vb{w}\right> - \lambda \left< \vb{w}, \vb{v} - \lambda \vb{w} \right> \\
        &= \left< \vb{v}, \vb{v} \right> - \overline{\lambda} \left< \vb{v}, \vb{w} \right> - \lambda \left< \vb{w}, \vb{v} \right> + \abs{\lambda}^{2} \left< \vb{w}, \vb{w} \right>
    \end{align*}
    
    \begin{equation}\label{eqn:v-minus-lamba-w}
        \boxed{\norm{\vb{v} - \lambda \vb{w}}^{2} = \norm{\vb{v}}^{2} - \overline{\lambda} \left< \vb{v},\vb{w} \right> - \lambda \overline{ \left< \vb{v},\vb{w} \right>} + \abs{\lambda}^{2} \norm{\vb{w}}^{2}}
    \end{equation} 
    Subtracting \Cref{eqn:v-minus-lamba-w} from \Cref{eqn:v-plus-lamba-w}, we have 
    \begin{align*}
        \norm{\vb{v} + \lambda \vb{w}}^{2}- \norm{\vb{v} - \lambda \vb{w}}^{2} &= 2 \overline{\lambda} \left< \vb{v}, \vb{w} \right> + 2\lambda \overline{ \left< \vb{v}, \vb{w} \right>} \\
        &= 0 \tag{since $\left< \vb{v},\vb{w} \right>  = 0$}
    \end{align*}
    Therefore \( \norm{\vb{v} + \lambda \vb{w}}^{2} = \norm{\vb{v} - \lambda \vb{w}}^{2} \), which implies \(  \norm{\vb{v} + \lambda \vb{w}} = \norm{\vb{v} - \lambda \vb{w}}  \) for all \(  \lambda \in \mathbb{K} \).
    
    \medskip
    
    \noindent \( \left( \Leftarrow \right) \) Now suppose that \(  \norm{\vb{v} + \lambda \vb{w}} = \norm{\vb{v} - \lambda \vb{w}}  \) for all \( \lambda \in \mathbb{K} \). Then \( \norm{\vb{v} + \lambda \vb{w}}^{2} = \norm{\vb{v} - \lambda \vb{w}}^{2} \) for all \( \lambda \in \mathbb{K} \). 
    
    Using equations \Cref{eqn:v-plus-lamba-w} and \Cref{eqn:v-minus-lamba-w}, we have
    \begin{align*}
        0 &= \norm{\vb{v} + \lambda \vb{w}}^{2}- \norm{\vb{v} - \lambda \vb{w}}^{2} \\
        &= 2 \overline{\lambda} \left< \vb{v}, \vb{w} \right> + 2\lambda \overline{\left<  \vb{v}, \vb{w} \right>}
    \end{align*}
    for all \( \lambda \in \mathbb{K} \). 
    
    \textbf{Case 1:} If \( \mathbb{K} = \mathbb{R} \), then \( \overline{\lambda} = \lambda \) and \( \overline{\left< \vb{v}, \vb{w} \right>} = \left< \vb{v}, \vb{w} \right> \). Setting \( \lambda = 1 \), we get
    \[ 0 = 4\left< \vb{v}, \vb{w} \right>, \]
    so \( \left< \vb{v}, \vb{w} \right> = 0 \).
    
    \textbf{Case 2:} If \( \mathbb{K} = \mathbb{C} \), the equation \( 2\overline{\lambda}\left< \vb{v}, \vb{w} \right> + 2\lambda\overline{\left< \vb{v}, \vb{w} \right>} = 0 \) must hold for all \( \lambda \in \mathbb{C} \). 
    
    Setting \( \lambda = 1 \): 
    \[ 2\left< \vb{v}, \vb{w} \right> + 2\overline{\left< \vb{v}, \vb{w} \right>} = 0 \implies \Re\left(\left< \vb{v}, \vb{w} \right>\right) = 0. \]
    
    Setting \( \lambda = i \): 
    \[ 2(-i)\left< \vb{v}, \vb{w} \right> + 2(i)\overline{\left< \vb{v}, \vb{w} \right>} = 0 \implies -i\left< \vb{v}, \vb{w} \right> + i\overline{\left< \vb{v}, \vb{w} \right>} = 0 \]
    \[ \implies \overline{\left< \vb{v}, \vb{w} \right>} = \left< \vb{v}, \vb{w} \right> \implies \Im\left(\left< \vb{v}, \vb{w} \right>\right) = 0. \]
    
    Since both the real and imaginary parts of \( \left< \vb{v}, \vb{w} \right> \) are zero, we conclude \( \left< \vb{v}, \vb{w} \right> = 0 \).
\end{solution}


\begin{lemma}\label{2025-10-06 17:46:35}
    Suppose that \( \mathbf{V} \) is a real inner product space and that 
    \[ \norm{\vb{v} + \vb{w}}^{2}= \norm{\vb{v}}^{2} + \norm{\vb{w}}^{2} .\]
    Then \( \left< \vb{v},\vb{w} \right> = 0 \).
\end{lemma}
\begin{proof}
    If \(  \norm{\vb{v} + \vb{w}}^{2}= \norm{\vb{v}}^{2} + \norm{\vb{w}}^{2}  \) then \(  \norm{\vb{v} + \vb{w}}^{2}- \norm{\vb{v}}^{2} - \norm{\vb{w}}^{2} =0  \). So 
    \begin{align*}
        0 &= \left< \vb{v} + \vb{w}, \vb{v}+ \vb{w}\right> - \left< \vb{v},\vb{v} \right> - \left< \vb{w},\vb{w} \right> \\
        &=\left< \vb{v},\vb{v} \right> + 2 \left< \vb{v},\vb{w} \right> + \left<  \vb{w},\vb{w} \right>- \left<  \vb{v},\vb{v} \right> - \left<  \vb{w}, \vb{w} \right> \\
        0 &= 2 \left< \vb{v},\vb{w} \right>
    \end{align*}
    This proves the result. 
\end{proof}


\begin{exercise}
    Prove \cref{2025-10-06 17:46:35} using the contrapositive.
\end{exercise}
\begin{solution}
    Suppose that \( \left< \vb{v},\vb{w} \right> = \lambda \) for \( \lambda \neq 0 \). Then, by using a similar argument as above, we can show that
    \[ \left< \vb{v} + \vb{w}, \vb{v}+ \vb{w}\right> - \left< \vb{v},\vb{v} \right> - \left< \vb{w},\vb{w} \right> = 2\lambda \]
\end{solution}


\begin{exercise}
    Show that the result laid out in \cref{2025-10-06 17:46:35} is not necessarily true in a complex vector space.
\end{exercise}
\begin{solution}
  Take \( \mathbb{C} \) to be the vector space over itself and let \( \vb{v}= i \) and \( \vb{w} =1 \). 
  We have 
  \begin{align*}
    \norm{\vb{v}+ \vb{w}}^{2} - \norm{\vb{v}}^{2}- \norm{\vb{w}}^{2} &= \norm{1+i}^{2} - \norm{1}^{2} - \norm{i}^{2}\\
    &= 2 -1 -1 \\
    &=0
  \end{align*}
  But \[ \left< \vb{v},\vb{w} \right> = \left< i,1 \right> = i.\]
\end{solution}


\begin{exercise}\label{exc:equality-for-norm-squared}
    Suppose that \( \mathbf{V} \) is an inner product space over \( \mathbb{C} \). For every \( \vb{v},\vb{w} \in \mathbf{V} \). Show that 
    \[ \norm{\vb{v}   + \vb{w}}^{2} = \norm{\vb{v}}^{2} + \norm{\vb{w}}^{2} + 2 \Re \left( \left< \vb{v},\vb{w} \right> \right) .\]
\end{exercise}
\begin{solution}
    We can take \Cref{eqn:v-plus-lamba-w} and let \( \lambda =1 \) to get 
    \begin{align*}
        \norm{\vb{v} + \vb{w}}^{2} &= \norm{\vb{v}}^{2} + \norm{\vb{w}}^{2} + \left< \vb{v},\vb{w} \right> + \overline{\left< \vb{v},\vb{w} \right>} \\
        &= \norm{\vb{v}}^{2} + \norm{\vb{w}}^{2} + 2 \Re \left( \left< \vb{v},\vb{w} \right> \right)
    \end{align*}
\end{solution}

\begin{exercise}
  Suppose that \( \vb{u}, \vb{v} \in \mathbf{V} \) a complex inner-product space, such that \( \norm{\vb{u}}^{2} + \norm{\vb{v}}^{2} = \norm{\vb{u} + \vb{v}}^{2} \). Is it necessarily true that \( \left< \vb{u}, \vb{v} \right> = 0 \)? If not, provide a counter-example
\end{exercise}
\begin{solution}
    \Cref{exc:equality-for-norm-squared} suggests that it is not true. Let \( \mathbf{V} = \mathbb{C} \) and let \( \vb{u} = 1+i \) and \( \vb{v} = 1-i \). On one hand, we have 
    \begin{align*}
        \norm{\vb{u} + \vb{v}}^{2} -\norm{\vb{u}}^{2} - \norm{\vb{v}}^{2} &= \norm{ 1+ i + 1-i}^{2} - \norm{ 1+i}^{2} - \norm{1-i}^{2} \\
        &= 4 - 2 -2 \\
        &= 0
    \end{align*}
    So  \( \norm{\vb{u}}^{2} + \norm{\vb{v}}^{2} = \norm{\vb{u} + \vb{v}}^{2} \) But on the other hand, 
    \begin{align*}
        \left< \vb{u}, \vb{v} \right> &= \left( 1+i \right) \cdot \overline{1-i} \\
        &= (1+i) \cdot (1+i) \\
        &= 2i
    \end{align*}
    So the claim is false.
\end{solution}


\begin{exercise}
    Let \( \vb{u}, \vb{v}, \vb{w} \) be vectors in an inner-product space \( \mathbf{V} \). Show that \( \norm{\vb{u} - \vb{w}} = \norm{\vb{u} -\vb{v}} + \norm{\vb{v} - \vb{w}} \) if and only if there exists a real number \( t \in \left[ 0,1 \right] \) such that \( \vb{v} = t \vb{u} + \left( 1-t  \right)\vb{w} \).
\end{exercise}
\begin{solution}
    \( (\Leftarrow) \) We will start with the reverse direction because it's easier. 
    Suppose there exists a \( t \in [0,1] \) such that 
    \[
        \vb{v} = t \vb{u} + (1-t)\vb{w}.
    \]
    If \( t = 0 \) or \( t = 1 \), then \( \vb{v} = \vb{w} \) or \( \vb{v} = \vb{u} \) respectively, and the result is trivial. 
    So assume \( t \in (0,1) \). Then 
    \begin{align*}
        \norm{\vb{u} - \vb{v}} + \norm{\vb{v} - \vb{w}} 
        &= \norm{\vb{u} - \left( t \vb{u} + (1-t)\vb{w} \right)} 
        + \norm{t \vb{u} + (1-t)\vb{w} - \vb{w}} \\
        &= \norm{(1-t)(\vb{u}-\vb{w})} + \norm{t(\vb{u}-\vb{w})} \\
        &= (1-t)\norm{\vb{u}-\vb{w}} + t\norm{\vb{u}-\vb{w}}
        \quad\text{\footnotesize (since $t\in(0,1)$, it can be taken out of the norm without absolute value)}\\
        &= \norm{\vb{u}-\vb{w}},
    \end{align*}
    which is what we wanted. \\[6pt]

    \( (\Rightarrow) \) Suppose that  
    \[
        \norm{\vb{u} - \vb{w}} = \norm{\vb{u} - \vb{v}} + \norm{\vb{v} - \vb{w}}.
    \]
    Set \( \vb{x} = \vb{u} - \vb{v} \) and \( \vb{y} = \vb{v} - \vb{w} \). Then we know that 
    \[
        \norm{\vb{x} + \vb{y}} \le \norm{\vb{x}} + \norm{\vb{y}},
    \]
    with equality if and only if \( \vb{x} = \lambda \vb{y} \) for some \( \lambda \ge 0 \).  
    Since we are assuming equality, it follows that 
    \[
        \vb{u} - \vb{v} = \lambda(\vb{v} - \vb{w}),
    \]
    With some algebraic manipulation, we can see that 
    \[ \vb{v} = \frac{1}{1+ \lambda} \vb{u}  + \frac{\lambda }{1+ \lambda} \vb{w},\]
    we can set \( t = \frac{1}{1+\lambda} \) so \( (1-t) = \frac{\lambda}{ 1 + \lambda} \) and we are done.
\end{solution}



\begin{theorem}[The Polarization Identity]\label{thm:polarization-identiy}
    If \( \mathbf{V} \) is a complex inner product space, then 
    \[\left< \vb{u}, \vb{v} \right> = \frac{1}{4} \left( \norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2} + i \norm{\vb{u} + i \vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2} \right) \text{ .}\]
\end{theorem}
\begin{proof}
    We just calculate the right-hand side. 
\begin{align*}
    \norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2} + i \norm{\vb{u} + i \vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2}  &=  \left< \vb{u} + \vb{v}, \vb{u} + \vb{v} \right> - \left< \vb{u}- \vb{v}, \vb{u}- \vb{v} \right> + i \left< \vb{u} + i\vb{v}, \vb{u} + i\vb{v} \right> - i \left<  \vb{u} - i\vb{v}, \vb{u} - i \vb{v} \right> \\ \\
    &= \left< \vb{u}, \vb{u} + \vb{v} \right> + \left< \vb{v}, \vb{u} + \vb{v} \right> - \left< \vb{u}, \vb{u} - \vb{v} \right> + \left< \vb{v}, \vb{u} - \vb{v} \right> \\
    &+ i \left< \vb{u}, \vb{u} + i\vb{v} \right> + i\left< \vb{v}, \vb{u} + i\vb{v} \right> -i \left< \vb{u}, \vb{u}- i\vb{v} \right> - i\left< \vb{v}, \vb{u} - i\vb{v} \right> \\ \\
    &= \left<  \vb{u}, \vb{u} \right> + \left<  \vb{u}, \vb{v} \right> + \left< \vb{v}, \vb{u} \right> + \left<  \vb{v},\vb{v} \right> - \left< \vb{u}, \vb{u} \right> + \left< \vb{u}, \vb{v} \right> + \left< \vb{v}, \vb{u} \right> - \left< \vb{v},\vb{v} \right> \\
    &+ i \left< \vb{u}, \vb{u} \right> + \left< \vb{u}, \vb{v} \right> + i\left< \vb{v}, \vb{u} \right> + i^2 \left< \vb{v},\vb{v} \right> - i \left< \vb{u}, \vb{u} \right> + \left< \vb{u},\vb{v} \right> + i\left< \vb{v}, \vb{u} \right> - i^2 \left< \vb{v},\vb{v} \right> \\ \\
    &= \Ccancel[DeepRed]{ \left<  \vb{u}, \vb{u} \right> } + \left<  \vb{u}, \vb{v} \right> + \Ccancel[AzureBlue]{\left< \vb{v}, \vb{u} \right> } + \Ccancel[AmberOrange]{\left<  \vb{v},\vb{v} \right>}   -\Ccancel[DeepRed]{ \left<  \vb{u}, \vb{u} \right> } + \left< \vb{u}, \vb{v} \right> + \Ccancel[RoyalPurple]{\left< \vb{v}, \vb{u} \right>} -\Ccancel[AmberOrange]{\left<  \vb{v},\vb{v} \right>} \\
    &+ \Ccancel[GoldenYellow]{ i  \left< \vb{u}, \vb{u} \right> } + \left< \vb{u}, \vb{v} \right> + \Ccancel[AzureBlue]{i\left< \vb{v}, \vb{u} \right>} +  \Ccancel[Emerald]{ i^2 \left< \vb{v},\vb{v} \right>}  - \Ccancel[GoldenYellow]{ i  \left< \vb{u}, \vb{u} \right> }  + \left< \vb{u},\vb{v} \right> + \Ccancel[RoyalPurple]{i\left< \vb{v}, \vb{u} \right>} - \Ccancel[Emerald]{ i^2 \left< \vb{v},\vb{v} \right>} \\
    &= 4 \left<  \vb{u}, \vb{v} \right>
\end{align*}
    which is what we wanted to show. 
\end{proof}

 \textbf{Note:} An easy way to write (or remember) the polarization identity is \[ \boxed{\left< \vb{u}, \vb{v} \right> = \frac{1}{4} \left( \sum_{k=0}^{3}  i^{k} \norm{\vb{u} + i^{k} \vb{v}}^{2}\right)   \text{ .}} \] 

\begin{lemma}
    Suppose that \( \mathbf{V} \) and \( \mathbf{W} \) are complex inner product spaces and \( T \in \mathcal{L} \left( \mathbf{V}, \mathbf{W} \right) \). Then \( T \) preserves the inner product if and only if it preserves the induced norm. That is,
    \[ \left< \vb{x}, \vb{y} \right>_{\mathbf{V}} = \left< T \left( \vb{x} \right), T \left( \vb{y} \right)\right>_{\mathbf{W}} \text{ for all } \vb{x}, \vb{y} \in \mathbf{V}\]
    if and only if
    \[ \norm{\vb{x}}_{\mathbf{V}} = \norm{T \left( \vb{x} \right)}_{\mathbf{W}} \text{ for all } \vb{x} \in \mathbf{V}.\]
\end{lemma}
\begin{proof}
     \( \left( \Rightarrow \right) \) Suppose that \( T \) preserves the inner product. Then 
     \begin{align*}
        \norm{\vb{x}}_{\mathbf{V}} &= \sqrt{ \left< \vb{x}, \vb{x} \right>_{\mathbf{V}}} \\
        &= \sqrt{\left< T \left( \vb{x} \right), T \left( \vb{x} \right)\right>_{\mathbf{W}}} \\
        &= \norm{T \left( \vb{x} \right)}_{\mathbf{W}}
     \end{align*}
     So \( T \) also preserves norms. \\ 
     \( \left( \Leftarrow \right) \) Conversely if \( T \) preserves norms, then by the \hyperref[thm:polarization-identiy]{poloarization identity} 
     \begin{align*}
        \left< \vb{x}, \vb{y} \right>_{\mathbf{V}} &= \frac{1}{4} \left( \sum_{k=0}^{3} i^{k} \norm{\vb{x} + i^{k} \vb{y}}_{\mathbf{V}}^{2} \right) \\
        &= \frac{1}{4} \left( \sum_{k=0}^{3} i^{k} \norm{T \left( \vb{x} + i^{k} \vb{y} \right)}_{\mathbf{W}}^{2} \right) \\
        &=  \frac{1}{4} \left( \sum_{k=0}^{3} i^{k} \norm{T(\vb{x}) + i^{k} T(\vb{y})}_{\mathbf{W}}^{2} \right) \\
        &= \left< \vb{x}, \vb{y} \right>_{\mathbf{W}}
     \end{align*}
     So \( T \) also preserves the inner product.
 \end{proof}
 

\begin{exercise}\label{exc:re-and-im-polarization}
    Suppose that \( \mathbf{V} \) is a normed complex vector space and define the map \( p: \mathbf{V} \times \mathbf{V} \to \mathbb{C} \) given by 
    \[ p \left( \vb{u}, \vb{v} \right) = \frac{1}{4} \left( \sum_{k=0}^{3}  i^{k} \norm{\vb{u} + i^{k} \vb{v}}^{2}\right) \text{ .}\] Show that
    \[ \Im \left[ p \left(  \vb{u}, \vb{v} \right)  \right]= \Re \left[ p ( \vb{u}, i \vb{v}) \right]\]
\end{exercise}
\begin{solution}
    For the left-hand side, we have 
    \begin{align*}
        \Im \left[ p \left( \vb{u},\vb{v} \right) \right] &= \Im \left[ \frac{1}{4} \left( \norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2} + i \norm{\vb{u} + i \vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2} \right)  \right] \\
        &= \frac{1}{4} \left( \norm{\vb{u} + i \vb{v}}^{2} + \norm{\vb{u} - i\vb{v}}^{2} \right)
    \end{align*}
For the right-hand side, we have 
    \begin{align*}
        \Re \left[ p \left( \vb{u}, i\vb{v} \right) \right] &= \Re \left[  \frac{1}{4} \left( \norm{\vb{u} + i\vb{v}}^{2} - \norm{\vb{u} - i\vb{v}}^{2} + i \norm{\vb{u} - \vb{v}}^{2} - i \norm{\vb{u} + \vb{v}}^{2} \right)\right]\\
         &= \frac{1}{4} \left( \norm{\vb{u} + i \vb{v}}^{2} + \norm{\vb{u} - i\vb{v}}^{2} \right)
    \end{align*}
    
\end{solution}

\begin{exercise}\label{exc:polarization-zero}
    Let the conditions of \cref{exc:re-and-im-polarization} hold. Then 
    \[ p \left( \vb{0}, \vb{v} \right) = p \left( \vb{v},\vb{0} \right) = 0 \quad \text{for all } \vb{v} \in \mathbf{V}. \]
\end{exercise}
\begin{solution}
    We have 
    \begin{align*}
        p \left( \vb{0},\vb{v} \right) &= \frac{1}{4}\left( \norm{\vb{0} + \vb{v}}^{2}  -\norm{\vb{0} - \vb{v}}^{2} + i \norm{\vb{0} + i\vb{v}}^{2} - i \norm{\vb{0} -i \vb{v}}^{2}\right) \\
        &= \frac{1}{4} \left( \norm{\vb{v}}^{2} - \norm{- \vb{v}}^{2} + i \norm{i\vb{v}}^{2} - i \norm{-i \vb{v}}^{2} \right) \\
        &= \frac{1}{4} \left(  \norm{\vb{v}}^{2} - \norm{\vb{v}}^{2} + i\norm{\vb{v}}^{2} - i \norm{\vb{v}}^{2} \right)\\
        &= 0
    \end{align*}
    Showing \( p \left( \vb{v}, \vb{0} \right) =0 \) is similar. 
\end{solution}



\begin{lemma}[The Parallelogram Law]
     Suppose that \( \mathbf{V} \) is an inner product space. Then for all \( \vb{u},\vb{v} \in \mathbf{V} \), we have 
    \[ \norm{\vb{u} + \vb{v}}^{2} + \norm{\vb{u} -\vb{v}}^{2} = 2 \left( \norm{\vb{u}}^{2} + \norm{\vb{v}}^{2} \right) \text{ .}\]
\end{lemma}
\begin{proof}
    This is a straight forward calculation. 
    \begin{align*}
        \norm{\vb{u} + \vb{v}}^{2} + \norm{\vb{u} -\vb{v}}^{2} &= \left< \vb{u} + \vb{v}, \vb{u} + \vb{v} \right> + \left< \vb{u} -\vb{v}, \vb{u} -\vb{v} \right> \\
        &= \left< \vb{u}, \vb{u} + \vb{v} \right> + \left<  \vb{v},\vb{u} + \vb{v} \right> + \left< \vb{u}, \vb{u}- \vb{v} \right> - \left< \vb{v}, \vb{u}- \vb{v} \right> \\
        &= \left< \vb{u}, \vb{u} \right> + \left< \vb{u},\vb{v} \right> + \left< \vb{v}, \vb{u} \right> + \left<  \vb{v},\vb{v} \right> + \left<  \vb{u}, \vb{u} \right> - \left< \vb{u}, \vb{v} \right> - \left<  \vb{v}, \vb{u} \right> + \left<  \vb{v},\vb{v} \right>\\
        &= \left< \vb{u}, \vb{u} \right> + \Ccancel[DeepRed]{ \left< \vb{u},\vb{v} \right>} + \Ccancel[AmberOrange]{ \left< \vb{v}, \vb{u} \right>}  + \left<  \vb{v},\vb{v} \right> + \left<  \vb{u}, \vb{u} \right> - \Ccancel[DeepRed]{ \left< \vb{u},\vb{v} \right>} - \Ccancel[AmberOrange]{ \left< \vb{v}, \vb{u} \right>} + \left<  \vb{v},\vb{v} \right> \\
        &= 2 \left< \vb{u} ,\vb{u} \right> + 2 \left<  \vb{v},\vb{v} \right>
    \end{align*}
   So 
   \[ \boxed{ \norm{\vb{u} + \vb{v}}^{2} + \norm{\vb{u} -\vb{v}}^{2} = 2 \left( \norm{\vb{u}}^{2} + \norm{\vb{v}}^{2} \right) \text{ .}} \] 
\end{proof}


\begin{theorem}
    If \( \mathbf{V} \) is a normed vector space with norm \( \norm{ \cdot} \) which satisfies the parallelogram law for every \( \vb{u}, \vb{v} \in \mathbf{V} \), then there exists an inner product \( \left< \cdot, \cdot \right> \) whose induced norm is exactly \( \norm{ \cdot} \).
\end{theorem}
\begin{proof}
We will use the \hyperref[thm:polarization-identiy]{polarization identity} to define our candidate inner product. 
\[ \left< \vb{u}, \vb{v} \right> = \frac{1}{4} \left( \sum_{k =0}^{3} i^{k} \norm{\vb{u} + i^{k} \vb{v}}^{2} \right) \text{ .}\]
We need to show that the conditions laid out in \cref{def:inner-product} are satisfied. \\ 
\begin{description}
    \item[\textbf{Conjugate symmetry:}] $ $\\ We need to show that \( \Re{\left( \left< \vb{u},\vb{v} \right> \right)} =\Re{\left( \left< \vb{v},\vb{u} \right> \right)}  \) and  \( \Im{\left( \left< \vb{u},\vb{v} \right> \right)} = -\Im{\left( \left< \vb{v},\vb{u} \right> \right)}  \). In that regard, we have 
    \begin{align*}
        \Re{\left( \left< \vb{u},\vb{v} \right> \right)} &= \Re \left[  \frac{1}{4} \left(\norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2} + i \norm{\vb{u} + i \vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2}\right) \right] \\
        &= \frac{1}{4} \left(   \norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2}  \right) \\
        &=\frac{1}{4} \left(   \norm{\vb{v} + \vb{u}}^{2} - \norm{-1 \left( \vb{v}- \vb{u} \right)}^{2}  \right) \\
        &= \frac{1}{4} \left(   \norm{\vb{v} + \vb{u}}^{2} - \abs{-1}^{2}\; \norm{\vb{v}- \vb{u}}^{2}\right)\\
         &= \frac{1}{4} \left(   \norm{\vb{v} + \vb{u}}^{2} -  \norm{\vb{v}- \vb{u}}^{2}\right)\\
         &= \Re \left[ \frac{1}{4}  \left(   \norm{\vb{v} + \vb{u}}^{2} -  \norm{\vb{v}- \vb{u}}^{2}+ i \norm{\vb{v} + i \vb{u}}^{2} - i \norm{\vb{v}- i\vb{u}}^{2} \right) \right] \\
         &= \Re \left( \left< \vb{v},\vb{u} \right> \right) 
    \end{align*}
Similarly, we have 
\begin{align*}
    \Im \left( \left<  \vb{u}, \vb{v} \right> \right) 
    &= \Im \left[  \frac{1}{4} \left( \norm{\vb{u} + \vb{v}}^{2} - \norm{\vb{u} - \vb{v}}^{2} + i \norm{\vb{u} + i \vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2} \right)\right] \\
    &= \frac{1}{4} \Im \left( i \norm{\vb{u} + i\vb{v}}^{2} - i \norm{\vb{u} - i \vb{v}}^{2} \right) \\
    &= \frac{1}{4} \Re \left( \norm{\vb{u} + i\vb{v}}^{2} - \norm{\vb{u} - i \vb{v}}^{2} \right) \\
    &= -\frac{1}{4} \Re \left( \norm{\vb{v} + i\vb{u}}^{2} - \norm{\vb{v} - i\vb{u}}^{2} \right) \\
    &= -\Im \left( \left< \vb{v}, \vb{u} \right> \right).
\end{align*}
    So this shows that \( \left< \vb{u},\vb{v} \right> = \overline{\left< \vb{v}, \vb{u} \right>} \). This incidentally shows that \( \left< \vb{v},\vb{v} \right> \in \mathbb{R} \) for all \( \vb{v} \in \mathbf{V} \).\
    \item[\textbf{Non-negative and Definite:}] $ $ \\Suppose that \( \vb{v} \in \mathbf{V} \). Then 
    \begin{align*}
        \left< \vb{v},\vb{v} \right> &= \frac{1}{4} \left( \norm{\vb{v} + \vb{v}}^{2} + \norm{\vb{v} - \vb{v}}^{2} + i \norm{\vb{v} + i\vb{v}} ^{2} - i \norm{\vb{v} - i \vb{v}} ^{2}\right) \\
        &= \frac{1}{4} \left( \norm{2 \vb{v}}^{2} + i \norm{\left( 1+i  \right) \vb{v}}^{2} - i \norm{\left( 1-i \right) \vb{v}}^{2} \right) \\
        &= \frac{1}{4} \left( 4 \norm{\vb{v}}^{2} + 2i \norm{\vb{v}}^{2} - 2i \norm{ \vb{v}}^{2} \right) \\
        &= \norm{\vb{v}}^{2} 
    \end{align*}
  This tells us :
  \begin{enumerate}[label=\textbf{\roman*)}]
    \item \( \left< \vb{v},\vb{v} \right> \ge 0 \) since \( \norm{\vb{v}}^{2} \ge 0 \).
    \item \( \left< \vb{v},\vb{v} \right> =0\) if and only if \( \vb{v} = \vb{0} \) since \( \norm{\vb{v}}^{2} = 0 \) if and only if \( \vb{v}= \vb{0} \).
    \item That once we show that \( \left< \cdot, \cdot \right> \) is an inner product that \( \norm{ \cdot} \) is the induced norm.
  \end{enumerate}
  \item[\textbf{Additivity:}]$ $\\ We want to show $\langle \vb{u}+ \vb{v}, \vb{w} \rangle = \langle \vb{u}, \vb{w} \rangle + \langle \vb{v}, \vb{w} \rangle$ for all $\vb{u}, \vb{v}, \vb{w} \in \mathbf{V}$. The parallelogram law doesn't immediately suggest how to prove this. However, we observe that $\vb{u}$ and $\vb{v}$ play symmetric roles in the expression $\langle \vb{u}+ \vb{v}, \vb{w} \rangle$. As such, any identity we derive should treat them symmetrically. This guides us to apply the parallelogram law to expressions involving $\vb{u} + \vb{w}$ and $\vb{v} + \vb{w}$, which we'll then combine to obtain additivity.\\ 
  With that in mind, we apply the parallelogram law to obtain the following two equations 
  \begin{equation}\label{eqn:plus-w-over-two}
    \norm{\left( \vb{u} + \frac{\vb{w}}{2} \right)+ \left( \vb{v} + \frac{\vb{w}}{2} \right)}^{2} + \norm{\left( \vb{u} + \frac{\vb{w}}{2} \right)- \left( \vb{v} + \frac{\vb{w}}{2} \right)}^{2} = 2 \norm{\vb{u} + \frac{\vb{w}}{2}}^2 + 2 \norm{\vb{v} + \frac{\vb{w}}{2}}^2
  \end{equation}
    \begin{equation}\label{eqn:minus-w-over-two}
    \norm{\left( \vb{u} - \frac{\vb{w}}{2} \right)+ \left( \vb{v} - \frac{\vb{w}}{2} \right)}^{2} + \norm{\left( \vb{u} + \frac{\vb{w}}{2} \right)- \left( \vb{v} + \frac{\vb{w}}{2} \right)}^{2} = 2 \norm{\vb{u} - \frac{\vb{w}}{2}}^2 + 2 \norm{\vb{v} - \frac{\vb{w}}{2}}^2
  \end{equation}
  Subtracting \cref{eqn:minus-w-over-two} from \cref{eqn:plus-w-over-two}, we have 
  \begin{align*}
     \norm{\left( \vb{u} + \frac{\vb{w}}{2} \right)+ \left( \vb{v} + \frac{\vb{w}}{2} \right)}^{2} -  \norm{\left( \vb{u} - \frac{\vb{w}}{2} \right)+ \left( \vb{v} - \frac{\vb{w}}{2} \right)}^{2} &= 2 \left( \norm{\vb{u} + \frac{\vb{w}}{2}}^2 -  \norm{\vb{u} - \frac{\vb{w}}{2}}^2 \right) + 2 \left( \norm{\vb{v} + \frac{\vb{w}}{2}}^2 -  \norm{\vb{v} - \frac{\vb{w}}{2}}^2 \right) \\
     \norm{\vb{u} + \vb{v} + \vb{w}}^{2} - \norm{\vb{u} + \vb{v} -\vb{w}}^{2} &=  2 \left( \norm{\vb{u} + \frac{\vb{w}}{2}}^2 -  \norm{\vb{u} - \frac{\vb{w}}{2}}^2 \right) + 2 \left( \norm{\vb{v} + \frac{\vb{w}}{2}}^2 -  \norm{\vb{v} - \frac{\vb{w}}{2}}^2 \right) 
  \end{align*}
  \begin{equation}\label{eqn:real-part-of-inner}
      \Re \left[ \left< \vb{u}+ \vb{v}, \vb{w} \right> \right] = 2 \Re \left[ \left< \vb{u}, \frac{\vb{w}}{2} \right> \right] + 2 \Re \left[ \left< \vb{v},\frac{\vb{w}}{2} \right> \right]
  \end{equation}
  Applying the result of \cref{exc:polarization-zero} to \cref{eqn:real-part-of-inner} by setting \( \vb{u} = \vb{0} \), we have 
  \begin{align*}
    \Re \left[ \left< \vb{0}+ \vb{v}, \vb{w} \right> \right] &= 2 \Re \left[ \left< \vb{0}, \frac{\vb{w}}{2} \right> \right] + 2 \Re \left[ \left<  \vb{v},\frac{\vb{w}}{2} \right> \right] 
  \end{align*}
  Similarly setting \( \vb{v} = \vb{0} \), we have the two equations
  \begin{equation}\label{2025-10-05 10:14:44}
    \colorboxed{DeepRed}{ \Re \left[ \left< \vb{v}, \vb{w} \right> \right] = 2 \Re \left[ \left< \vb{v}, \frac{\vb{w}}{2} \right> \right] } \quad \text{and} \quad  \colorboxed{AmberOrange}{ \Re \left[ \left< \vb{v}, \vb{w} \right> \right] = 2 \Re \left[ \left< \vb{v}, \frac{\vb{w}}{2} \right> \right] }
  \end{equation}
  Applying \cref{2025-10-05 10:14:44} to \cref{eqn:real-part-of-inner}, we have 
  \begin{align*}
     \Re \left[ \left< \vb{u}+ \vb{v}, \vb{w} \right> \right] &=  \colorboxed{DeepRed}{ 2 \Re \left[ \left< \vb{v}, \frac{\vb{w}}{2} \right> \right] } +  \colorboxed{AmberOrange}{ 2 \Re \left[ \left< \vb{v}, \frac{\vb{w}}{2} \right> \right] }\\
     &=     \colorboxed{DeepRed}{ \Re \left[ \left< \vb{v}, \vb{w} \right> \right]  }  +\colorboxed{AmberOrange}{ \Re \left[ \left< \vb{v}, \vb{w} \right> \right]}
  \end{align*}
  This shows that \( \Re \left[\left< \vb{u} + \vb{v}, \vb{w} \right> \right] \) is additive. Now we need to show that \( \Im \left[  \left< \vb{u} + \vb{v}, \vb{w} \right> \right] \) is additive. 
  \begin{align*}
    \Im \left[  \left< \vb{u} + \vb{v}, \vb{w} \right> \right] &= \Re \left[\left< \vb{u} + \vb{v}, i\vb{w} \right> \right] \tag*{By \cref{exc:re-and-im-polarization}} \\
    &= \Re \left[ \left< \vb{u}, i \vb{w} \right> \right] +  \Re \left[ \left< \vb{v}, i \vb{w} \right> \right] \\
    &=   \Im \left[  \left< \vb{u}, \vb{w} \right> \right]  +   \Im \left[  \left<  \vb{v}, \vb{w} \right> \right] 
  \end{align*}
  Finally putting it all together 
  \begin{align*}
    \left< \vb{u} + \vb{v}, \vb{w} \right> &=  \Re \left[  \left< \vb{u} + \vb{v}, \vb{w} \right> \right] +  \Im \left[  \left< \vb{u} + \vb{v}, \vb{w} \right> \right] i \\
    &= \left(  \Re \left[  \left< \vb{u} , \vb{w} \right> \right] + \Re \left[  \left< \vb{v}, \vb{w} \right> \right]\right) + \left(  \Im \left[  \left< \vb{u}, \vb{w} \right> \right] +  \Im \left[  \left<  \vb{v}, \vb{w} \right> \right] \right)i \\
    &= \left(  \Re \left[  \left< \vb{u} , \vb{w} \right> \right]  +  \Im \left[  \left< \vb{u} , \vb{w} \right> \right] i\right) +  \left(  \Re \left[  \left< \vb{v} , \vb{w} \right> \right]  +  \Im \left[  \left< \vb{v} , \vb{w} \right> \right] i\right)\\
    &= \left< \vb{u}, \vb{w} \right> + \left<  \vb{v},\vb{w} \right>
  \end{align*}
  With that, we have shown additivity. 
\item[\textbf{Homogeneity:}] $ $\\ We want to show that for each $\lambda \in \mathbb{C}$ and $\vb{u}, \vb{v} \in \mathbf{V}$, we have 
\[ \langle \lambda \vb{u}, \vb{v} \rangle = \lambda \langle \vb{u}, \vb{v} \rangle. \]
The proof proceeds by gradually extending the class of scalars for which homogeneity holds. We first establish the result for $\lambda \in \mathbb{N}$, then extend successively to $\lambda \in \mathbb{Z}$, then $\lambda \in \mathbb{Q}$, then $\lambda \in \mathbb{R}$, and finally to $\lambda \in \mathbb{C}$.
    \begin{description}
    \item[\( \bullet \) For \( \lambda \in \mathbb{N} \):]$ $\\
    We will prove this by induction while \( \lambda =1 \) is a perfectly acceptable base case. However, it is trivial and won't provide us with any insight on how to tackle the inductive step. So let us set the base case \(  \lambda =2 \). \\ 
    \textbf{Base case:} For \( \lambda =2 \), we have 
        \begin{align*}
            \left< 2 \vb{u}, \vb{v} \right> &= \left< \vb{u} + \vb{u}, \vb{v} \right> \\
            &= \left< \vb{u}, \vb{v} \right> + \left< \vb{u}, \vb{v} \right> \tag*{Since we have established additivity.} \\
            &= 2 \left< \vb{u}, \vb{v} \right>
        \end{align*}
    \textbf{Inductive step:}  Suppose that \( \left< \lambda \vb{u}, \vb{v} \right> = \lambda \left< \vb{u}, \vb{v} \right>\). Then 
        \begin{align*}
            \left< (\lambda+1) \vb{u}, \vb{v} \right> &= \left< \lambda \vb{u} + \vb{u}, \vb{v} \right> \\
            &=\left<  \lambda \vb{u} , \vb{v} \right> + \left< \vb{u}, \vb{v} \right> \\
            &= \lambda \left<  \vb{u}, \vb{v} \right> + \left<  \vb{u}, \vb{v} \right> \tag*{By the inductive hypothesis} \\
            &= \left( \lambda+1 \right) \left< \vb{u},\vb{v} \right>
        \end{align*}
        So \( \langle \lambda \vb{u}, \vb{v} \rangle = \lambda \langle \vb{u}, \vb{v} \rangle \) for every \( \lambda \in \mathbb{N} \).
    \item[$\bullet$ For \( \lambda \in \mathbb{Z} \):] $ $\\ 
    We just need to show the result for negative integers here. In other words, if \( \lambda > 0 \), then we need to show 
    \[ \left<  - \lambda \vb{u}, \vb{v} \right> = - \lambda \left< \vb{u}, \vb{v} \right> .\]
    \begin{align*}
        0 &= \left< 0 \vb{u}, \vb{v} \right>\\
        &=\left< \left( \lambda -\lambda \right) \vb{u},\vb{v} \right>\\
        &= \left< \lambda \vb{u} + \left( -\lambda \right)\vb{u}, \vb{v} \right> \\
        &= \left< \lambda \vb{u}, \vb{v} \right> +  \left< - \lambda \vb{u}, \vb{v} \right> \\
       0 &= \lambda \left<  \vb{u}, \vb{v} \right> + \left< - \lambda \vb{u}, \vb{v} \right>
    \end{align*}
    This shows that \(  \left<  - \lambda \vb{u}, \vb{v} \right> = - \lambda \left< \vb{u}, \vb{v} \right> \).
    \item[$\bullet$ For \( \lambda \in \mathbb{Q} \):] $ $\\ 
    Suppose that \( \lambda = \frac{p }{q} \) for \( p, q \in \mathbb{Z} \) and \(  q> 0 \). Then 
    \begin{align*}
        p\left< \vb{u}, \vb{v}  \right> &= \left< p \vb{u}, \vb{v} \right> \\
        &= \left< q \left( \frac{p}{q} \vb{u} \right) , \vb{v} \right> \\
        p \left<  \vb{u}, \vb{v} \right> &= q \left< \frac{p }{q} \vb{u},\vb{v} \right>
    \end{align*}
    Dividing both sides by \( q \) yields the desired result. 
    \item[$\bullet$ For \( \lambda \in \mathbb{R} \): ] This is the trickiest one to show. First, we note that as $|\alpha| \to 0$, we have $\|\alpha \vb{u}\| \to 0$. Indeed, for any $\epsilon > 0$, if $|\alpha| < \frac{\epsilon}{\|\vb{u}\|}$, then $\|\alpha \vb{u}\| = |\alpha| \|\vb{u}\| < \epsilon$. (The case $\vb{u} = \vb{0}$ is trivial.) In particular, as $|\alpha| \to 0$, we have $\|\alpha \vb{u} + \beta \vb{v}\| \to |\beta|\|\vb{v}\|$. To see this, note that by the reverse triangle inequality:
\begin{align*}
\big| \;  \|\alpha \vb{u} + \beta \vb{v}\| - |\beta|\|\vb{v}\| \; \big| 
&=\big| \; \|\alpha \vb{u} + \beta \vb{v}\| - \|\beta \vb{v}\| \; \big| \\
& \le \norm{\alpha \vb{u} + \beta \vb{v} - \beta \vb{v}} \\
&\leq \|\alpha \vb{u}\| \\
&= |\alpha| \|\vb{u}\| \to 0.
\end{align*}
With that in mind, we can now prove that for \( \lambda \in \mathbb{R} \), we have \( \left< \lambda \vb{u}, \vb{v} \right> = \lambda \left<  \vb{u}, \vb{v} \right> \). First pick \( \mu \in \mathbb{Q} \) such that \( \abs{\lambda - \mu} \to 0 \). Then 
    \begin{align*}
        \abs{\left< \lambda \vb{u}, \vb{v} \right> - \lambda \left<  \vb{u}, \vb{v} \right>} &\le \abs{\left< \lambda \vb{u}, \vb{v} \right> - \left< \mu \vb{u}, \vb{v} \right>} + \abs{ \left< \mu \vb{u}, \vb{v} \right> - \mu \left<  \vb{u}, \vb{v} \right> } + \abs{\mu \left<  \vb{u}, \vb{v} \right> - \lambda \left<  \vb{u}, \vb{v} \right> } \\
        & = \abs{ \left< \left( \lambda - \mu \right) \vb{u}, \vb{v}\right>} + 0 + \abs{\left( \mu -\lambda \right) \left< \vb{u}, \vb{v} \right>}\\
        &= \abs{ \left< \left( \lambda - \mu \right) \vb{u}, \vb{v}\right>} \tag{Since $\abs{\left( \mu -\lambda \right) \left< \vb{u}, \vb{v} \right>} \to 0$.}
    \end{align*}
    Now we just need to show that \( \abs{ \left< \left( \lambda - \mu \right) \vb{u}, \vb{v}\right>} \to 0 \) as \( \abs{\lambda - \mu} \to 0 \). 
    \begin{align*}
        \abs{ \left< \left( \lambda - \mu \right) \vb{u}, \vb{v}\right>} &= \frac{1}{4} \abs{\norm{\left( \lambda - \mu \right) \vb{u} + \vb{v}}^{2} - \norm{\left( \lambda - \mu \right) \vb{u} - \vb{v}}^{2} + i \norm{\left( \lambda - \mu \right) \vb{u} + i \vb{v}}^{2} - i \norm{\left( \lambda - \mu \right) \vb{u} - i\vb{v}}^{2}} \\
        & \to \frac{1}{4}\abs{\norm{\vb{v}}^{2} - \norm{\vb{v}}^{2} + i\norm{\vb{v}}^{2} - i \norm{\vb{v}}^{2}} \tag{By our earlier discussion.}\\
        &= 0
    \end{align*}
    \item[$\bullet$ For \( \lambda \in \mathbb{C} \):] $ $\\ 
    It is sufficient to show that \( \left< i \vb{u}, \vb{v} \right> = i \left< \vb{u}, \vb{v} \right> \), since we have demonstrated \( \mathbb{R} \)-linearity. In other words, if \( \left< \vb{u}, \vb{v} \right> = a+bi \), we need to show that \( \left< i \vb{u}, \vb{v} \right> = -b + ai\) or that \( \Re \left[ \left< \vb{u}, \vb{v} \right> \right] = \Im \left[ \left< i \vb{u}, \vb{v} \right> \right]\) and \( \Im \left[ \vb{u},\vb{v} \right] = - \Re \left[ i \vb{u}, \vb{v} \right] \). 
    So 
    \begin{align*}
        \Re \left[ \left< i \vb{u}, \vb{v} \right> \right] &= \Re \left[ \left< \vb{v}, i \vb{u} \right> \right] \\
        &= \Im \left[ \left< \vb{v}, \vb{u} \right>  \right]\\
        &= - \Im \left[ \left< \vb{u}, \vb{v} \right> \right]
    \end{align*}
    and 
    \begin{align*}
        \Im \left[ \left< i \vb{u},\vb{v} \right> \right] &= \Re \left[ \left<  i \vb{u}, i \vb{v} \right> \right] \\
        &= \Re \left[  \left< \vb{u}, \vb{v} \right> \right] \tag{Use the definition of $\left< \vb{u},\vb{v} \right>$}
    \end{align*}
    This shows that \( \left< i \vb{u} , \vb{v} \right> = i \left<  \vb{u}, \vb{v} \right> \). Now set \( \lambda = \alpha + \beta i \) and we can apply \( \mathbb{R} \)-linearity 
    \begin{align*}
        \left< \lambda \vb{u}, \vb{v} \right> &= \left< \left( \alpha + \beta i \right) \vb{u}, \vb{v}\right> \\
        &= \left< \alpha \vb{u} + \beta i \vb{u}, \vb{v} \right> \\
        &= \left< \alpha \vb{u}, \vb{v} \right> + \left<  \beta i \vb{u}, \vb{v} \right> \\
        &= \alpha \left< \vb{u}, \vb{v} \right> + \beta \left<  i \vb{u}, \vb{v} \right>\\ 
        &= \alpha \left< \vb{u}, \vb{v} \right> + \beta i\left<   \vb{u}, \vb{v} \right> \\
        &= \left( \alpha + \beta i \right) \left< \vb{u}, \vb{v} \right> \\
        &= \lambda \left< \vb{u}, \vb{v} \right>
    \end{align*}
    
    \end{description}
\end{description}
With that, the proof is (finally) complete!
\end{proof}


